{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Lifespan Prediction\n",
    "\n",
    "This notebook demonstrates how to use the refactored `lifespan_predictor` package to:\n",
    "1. Load and clean CSV data\n",
    "2. Run featurization with new modules\n",
    "3. Generate fingerprints\n",
    "4. Save processed data\n",
    "\n",
    "The refactored code provides a clean, modular interface compared to the original notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Import from the refactored package\n",
    "from lifespan_predictor.config import Config\n",
    "from lifespan_predictor.data.preprocessing import load_and_clean_csv, validate_smiles_list\n",
    "from lifespan_predictor.data.featurizers import CachedGraphFeaturizer\n",
    "from lifespan_predictor.data.fingerprints import FingerprintGenerator\n",
    "from lifespan_predictor.utils.logging import setup_logger\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logger(\"preprocessing\", level=\"INFO\")\n",
    "logger.info(\"Starting data preprocessing notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Configuration\n",
    "\n",
    "Load configuration from YAML file. You can modify `default_config.yaml` or create your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = \"../lifespan_predictor/config/default_config.yaml\"\n",
    "config = Config.from_yaml(config_path)\n",
    "\n",
    "# Display key configuration parameters\n",
    "logger.info(f\"Configuration loaded from: {config_path}\")\n",
    "logger.info(f\"Train CSV: {config.data.train_csv}\")\n",
    "logger.info(f\"Test CSV: {config.data.test_csv}\")\n",
    "logger.info(f\"Output directory: {config.data.output_dir}\")\n",
    "logger.info(f\"Using cache: {config.featurization.use_cache}\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(config.data.graph_features_dir, exist_ok=True)\n",
    "os.makedirs(config.data.fingerprints_dir, exist_ok=True)\n",
    "os.makedirs(config.data.output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Clean Training Data\n",
    "\n",
    "The `load_and_clean_csv` function handles:\n",
    "- Loading CSV files\n",
    "- Cleaning and canonicalizing SMILES\n",
    "- Removing invalid molecules\n",
    "- Logging statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean training data\n",
    "logger.info(\"Loading training data...\")\n",
    "train_df = load_and_clean_csv(\n",
    "    csv_path=config.data.train_csv,\n",
    "    smiles_column=config.data.smiles_column,\n",
    "    label_column=config.data.label_column\n",
    ")\n",
    "\n",
    "logger.info(f\"Training data loaded: {len(train_df)} molecules\")\n",
    "logger.info(f\"Label distribution:\\n{train_df[config.data.label_column].value_counts()}\")\n",
    "\n",
    "# Display first few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Clean Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean test data\n",
    "logger.info(\"Loading test data...\")\n",
    "test_df = load_and_clean_csv(\n",
    "    csv_path=config.data.test_csv,\n",
    "    smiles_column=config.data.smiles_column,\n",
    "    label_column=None  # Test data may not have labels\n",
    ")\n",
    "\n",
    "logger.info(f\"Test data loaded: {len(test_df)} molecules\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Graph Features\n",
    "\n",
    "The `CachedGraphFeaturizer` provides:\n",
    "- Automatic caching to disk\n",
    "- Parallel processing\n",
    "- Progress bars\n",
    "- Robust error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph featurizer with caching\n",
    "graph_featurizer = CachedGraphFeaturizer(\n",
    "    cache_dir=config.data.graph_features_dir,\n",
    "    max_atoms=config.featurization.max_atoms,\n",
    "    atom_feature_dim=config.featurization.atom_feature_dim,\n",
    "    n_jobs=config.featurization.n_jobs\n",
    ")\n",
    "\n",
    "logger.info(\"Generating graph features for training data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurize training data\n",
    "train_smiles = train_df[config.data.smiles_column].tolist()\n",
    "train_labels = train_df[config.data.label_column].values\n",
    "\n",
    "train_adj, train_features, train_labels_out = graph_featurizer.featurize(\n",
    "    smiles_list=train_smiles,\n",
    "    labels=train_labels,\n",
    "    force_recompute=False  # Use cache if available\n",
    ")\n",
    "\n",
    "logger.info(f\"Training graph features shape: adj={train_adj.shape}, features={train_features.shape}\")\n",
    "logger.info(f\"Training labels shape: {train_labels_out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurize test data\n",
    "logger.info(\"Generating graph features for test data...\")\n",
    "test_smiles = test_df[config.data.smiles_column].tolist()\n",
    "\n",
    "test_adj, test_features, _ = graph_featurizer.featurize(\n",
    "    smiles_list=test_smiles,\n",
    "    labels=None,\n",
    "    force_recompute=False\n",
    ")\n",
    "\n",
    "logger.info(f\"Test graph features shape: adj={test_adj.shape}, features={test_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Molecular Fingerprints\n",
    "\n",
    "The `FingerprintGenerator` generates:\n",
    "- Morgan fingerprints (hashed)\n",
    "- RDKit topological fingerprints (hashed)\n",
    "- MACCS keys (non-hashed)\n",
    "\n",
    "All with automatic caching and parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fingerprint generator\n",
    "fp_generator = FingerprintGenerator(\n",
    "    morgan_radius=config.featurization.morgan_radius,\n",
    "    morgan_nbits=config.featurization.morgan_nbits,\n",
    "    rdkit_fp_nbits=config.featurization.rdkit_fp_nbits,\n",
    "    n_jobs=config.featurization.n_jobs\n",
    ")\n",
    "\n",
    "logger.info(\"Generating fingerprints for training data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training fingerprints\n",
    "train_fp_hashed, train_fp_nonhashed = fp_generator.generate_fingerprints(\n",
    "    smiles_list=train_smiles,\n",
    "    cache_dir=config.data.fingerprints_dir\n",
    ")\n",
    "\n",
    "logger.info(f\"Training fingerprints shape: hashed={train_fp_hashed.shape}, non-hashed={train_fp_nonhashed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test fingerprints\n",
    "logger.info(\"Generating fingerprints for test data...\")\n",
    "test_fp_hashed, test_fp_nonhashed = fp_generator.generate_fingerprints(\n",
    "    smiles_list=test_smiles,\n",
    "    cache_dir=config.data.fingerprints_dir\n",
    ")\n",
    "\n",
    "logger.info(f\"Test fingerprints shape: hashed={test_fp_hashed.shape}, non-hashed={test_fp_nonhashed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Data\n",
    "\n",
    "Save all processed features for later use in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training data\n",
    "train_output_dir = os.path.join(config.data.output_dir, \"train\")\n",
    "os.makedirs(train_output_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(train_output_dir, \"adj.npy\"), train_adj)\n",
    "np.save(os.path.join(train_output_dir, \"features.npy\"), train_features)\n",
    "np.save(os.path.join(train_output_dir, \"labels.npy\"), train_labels_out)\n",
    "np.save(os.path.join(train_output_dir, \"fp_hashed.npy\"), train_fp_hashed)\n",
    "np.save(os.path.join(train_output_dir, \"fp_nonhashed.npy\"), train_fp_nonhashed)\n",
    "\n",
    "# Save SMILES for reference\n",
    "train_df.to_csv(os.path.join(train_output_dir, \"processed_data.csv\"), index=False)\n",
    "\n",
    "logger.info(f\"Training data saved to: {train_output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data\n",
    "test_output_dir = os.path.join(config.data.output_dir, \"test\")\n",
    "os.makedirs(test_output_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(test_output_dir, \"adj.npy\"), test_adj)\n",
    "np.save(os.path.join(test_output_dir, \"features.npy\"), test_features)\n",
    "np.save(os.path.join(test_output_dir, \"fp_hashed.npy\"), test_fp_hashed)\n",
    "np.save(os.path.join(test_output_dir, \"fp_nonhashed.npy\"), test_fp_nonhashed)\n",
    "\n",
    "# Save SMILES for reference\n",
    "test_df.to_csv(os.path.join(test_output_dir, \"processed_data.csv\"), index=False)\n",
    "\n",
    "logger.info(f\"Test data saved to: {test_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining Data:\")\n",
    "print(f\"  - Molecules: {len(train_df)}\")\n",
    "print(f\"  - Graph features: {train_adj.shape}\")\n",
    "print(f\"  - Hashed fingerprints: {train_fp_hashed.shape}\")\n",
    "print(f\"  - Non-hashed fingerprints: {train_fp_nonhashed.shape}\")\n",
    "print(f\"  - Labels: {train_labels_out.shape}\")\n",
    "\n",
    "print(f\"\\nTest Data:\")\n",
    "print(f\"  - Molecules: {len(test_df)}\")\n",
    "print(f\"  - Graph features: {test_adj.shape}\")\n",
    "print(f\"  - Hashed fingerprints: {test_fp_hashed.shape}\")\n",
    "print(f\"  - Non-hashed fingerprints: {test_fp_nonhashed.shape}\")\n",
    "\n",
    "print(f\"\\nOutput Directories:\")\n",
    "print(f\"  - Training: {train_output_dir}\")\n",
    "print(f\"  - Test: {test_output_dir}\")\n",
    "print(f\"  - Cache: {config.data.graph_features_dir}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Preprocessing complete! Ready for model training.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
