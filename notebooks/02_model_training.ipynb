{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training for Lifespan Prediction\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load configuration from YAML\n",
    "2. Create datasets and dataloaders\n",
    "3. Initialize model and trainer\n",
    "4. Run training loop\n",
    "5. Visualize results\n",
    "\n",
    "This uses the refactored `lifespan_predictor` package for clean, modular training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Import from the refactored package\n",
    "from lifespan_predictor.config import Config\n",
    "from lifespan_predictor.data.dataset import LifespanDataset\n",
    "from lifespan_predictor.models.predictor import LifespanPredictor\n",
    "from lifespan_predictor.training.trainer import Trainer\n",
    "from lifespan_predictor.training.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from lifespan_predictor.training.metrics import AUC, Accuracy, F1Score, RMSE, MAE, R2Score\n",
    "from lifespan_predictor.utils.logging import setup_logger\n",
    "from lifespan_predictor.utils.visualization import plot_training_curves, plot_predictions\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logger(\"training\", level=\"INFO\")\n",
    "logger.info(\"Starting model training notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Configuration\n",
    "\n",
    "Load and validate configuration from YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = \"../lifespan_predictor/config/default_config.yaml\"\n",
    "config = Config.from_yaml(config_path)\n",
    "\n",
    "# Validate configuration\n",
    "config.validate()\n",
    "\n",
    "# Display key parameters\n",
    "logger.info(f\"Configuration loaded from: {config_path}\")\n",
    "logger.info(f\"Task: {config.training.task}\")\n",
    "logger.info(f\"Batch size: {config.training.batch_size}\")\n",
    "logger.info(f\"Max epochs: {config.training.max_epochs}\")\n",
    "logger.info(f\"Learning rate: {config.training.learning_rate}\")\n",
    "logger.info(f\"Device: {config.device.use_cuda and 'cuda' or 'cpu'}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if config.device.use_cuda and torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Preprocessed Data\n",
    "\n",
    "Load the data that was preprocessed in notebook 01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data_dir = os.path.join(config.data.output_dir, \"train\")\n",
    "\n",
    "logger.info(f\"Loading training data from: {train_data_dir}\")\n",
    "\n",
    "# Load CSV for SMILES\n",
    "train_df = pd.read_csv(os.path.join(train_data_dir, \"processed_data.csv\"))\n",
    "train_smiles = train_df[config.data.smiles_column].tolist()\n",
    "\n",
    "# Load preprocessed features\n",
    "train_adj = np.load(os.path.join(train_data_dir, \"adj.npy\"))\n",
    "train_features = np.load(os.path.join(train_data_dir, \"features.npy\"))\n",
    "train_labels = np.load(os.path.join(train_data_dir, \"labels.npy\"))\n",
    "train_fp_hashed = np.load(os.path.join(train_data_dir, \"fp_hashed.npy\"))\n",
    "train_fp_nonhashed = np.load(os.path.join(train_data_dir, \"fp_nonhashed.npy\"))\n",
    "\n",
    "logger.info(f\"Loaded {len(train_smiles)} training molecules\")\n",
    "logger.info(f\"Features shape: adj={train_adj.shape}, features={train_features.shape}\")\n",
    "logger.info(f\"Fingerprints shape: hashed={train_fp_hashed.shape}, non-hashed={train_fp_nonhashed.shape}\")\n",
    "logger.info(f\"Labels shape: {train_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Datasets and DataLoaders\n",
    "\n",
    "Create PyTorch Geometric datasets and dataloaders for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare graph features tuple\n",
    "graph_features = (train_adj, train_features)\n",
    "fingerprints = (train_fp_hashed, train_fp_nonhashed)\n",
    "\n",
    "# Create dataset\n",
    "logger.info(\"Creating PyTorch Geometric dataset...\")\n",
    "full_dataset = LifespanDataset(\n",
    "    smiles_list=train_smiles,\n",
    "    graph_features=graph_features,\n",
    "    fingerprints=fingerprints,\n",
    "    labels=train_labels\n",
    ")\n",
    "\n",
    "logger.info(f\"Dataset created with {len(full_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(full_dataset)),\n",
    "    test_size=config.training.val_split,\n",
    "    random_state=config.random_seed,\n",
    "    stratify=train_labels if config.training.stratify and config.training.task == \"classification\" else None\n",
    ")\n",
    "\n",
    "train_dataset = full_dataset[train_indices]\n",
    "val_dataset = full_dataset[val_indices]\n",
    "\n",
    "logger.info(f\"Split: {len(train_dataset)} training, {len(val_dataset)} validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.training.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0  # Set to 0 for Windows compatibility\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.training.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "logger.info(f\"Created dataloaders: {len(train_loader)} train batches, {len(val_loader)} val batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Model\n",
    "\n",
    "Create the LifespanPredictor model with the specified configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "logger.info(\"Initializing model...\")\n",
    "model = LifespanPredictor(config)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "logger.info(f\"Model initialized with {total_params:,} total parameters\")\n",
    "logger.info(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Display model architecture\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setup Training Components\n",
    "\n",
    "Configure optimizer, callbacks, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.training.learning_rate,\n",
    "    weight_decay=config.training.weight_decay\n",
    ")\n",
    "\n",
    "# Setup learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max' if config.training.task == 'classification' else 'min',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "logger.info(\"Optimizer and scheduler configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        patience=config.training.patience,\n",
    "        metric_name=config.training.main_metric,\n",
    "        mode='max' if config.training.task == 'classification' else 'min'\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        save_dir=config.data.output_dir,\n",
    "        metric_name=config.training.main_metric,\n",
    "        mode='max' if config.training.task == 'classification' else 'min'\n",
    "    ),\n",
    "    LearningRateScheduler(scheduler)\n",
    "]\n",
    "\n",
    "logger.info(f\"Configured {len(callbacks)} callbacks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initialize Trainer and Start Training\n",
    "\n",
    "Create the Trainer object and run the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    callbacks=callbacks,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "logger.info(\"Trainer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "logger.info(\"Starting training...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING STARTED\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "history = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Training Results\n",
    "\n",
    "Plot training curves and analyze model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plot_save_path = os.path.join(config.data.output_dir, \"training_curves.png\")\n",
    "plot_training_curves(history, save_path=plot_save_path)\n",
    "\n",
    "logger.info(f\"Training curves saved to: {plot_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal epochs: {len(history['train_loss'])}\")\n",
    "print(f\"Best epoch: {history.get('best_epoch', 'N/A')}\")\n",
    "print(f\"\\nFinal Training Loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {history['val_loss'][-1]:.4f}\")\n",
    "\n",
    "if config.training.task == 'classification':\n",
    "    print(f\"\\nBest Validation AUC: {max(history.get('val_AUC', [0])):.4f}\")\n",
    "    print(f\"Best Validation Accuracy: {max(history.get('val_Accuracy', [0])):.4f}\")\n",
    "    print(f\"Best Validation F1: {max(history.get('val_F1', [0])):.4f}\")\n",
    "else:\n",
    "    print(f\"\\nBest Validation RMSE: {min(history.get('val_RMSE', [float('inf')])):.4f}\")\n",
    "    print(f\"Best Validation MAE: {min(history.get('val_MAE', [float('inf')])):.4f}\")\n",
    "    print(f\"Best Validation R2: {max(history.get('val_R2', [0])):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate on Validation Set\n",
    "\n",
    "Load the best model and evaluate on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = os.path.join(config.data.output_dir, \"best_model.pt\")\n",
    "if os.path.exists(best_model_path):\n",
    "    logger.info(f\"Loading best model from: {best_model_path}\")\n",
    "    checkpoint = torch.load(best_model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    logger.info(\"Best model loaded successfully\")\n",
    "else:\n",
    "    logger.warning(\"Best model checkpoint not found, using current model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation set\n",
    "val_predictions = []\n",
    "val_targets = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        batch = batch.to(device)\n",
    "        outputs = model(batch)\n",
    "        \n",
    "        if config.training.task == 'classification':\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "        \n",
    "        val_predictions.append(outputs.cpu().numpy())\n",
    "        val_targets.append(batch.y.cpu().numpy())\n",
    "\n",
    "val_predictions = np.concatenate(val_predictions, axis=0)\n",
    "val_targets = np.concatenate(val_targets, axis=0)\n",
    "\n",
    "logger.info(f\"Generated predictions for {len(val_predictions)} validation samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "pred_plot_path = os.path.join(config.data.output_dir, \"validation_predictions.png\")\n",
    "plot_predictions(\n",
    "    y_true=val_targets,\n",
    "    y_pred=val_predictions,\n",
    "    save_path=pred_plot_path,\n",
    "    task=config.training.task\n",
    ")\n",
    "\n",
    "logger.info(f\"Prediction plot saved to: {pred_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Training Configuration and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save configuration used for training\n",
    "config_save_path = os.path.join(config.data.output_dir, \"training_config.yaml\")\n",
    "config.save(config_save_path)\n",
    "logger.info(f\"Configuration saved to: {config_save_path}\")\n",
    "\n",
    "# Save training history\n",
    "history_df = pd.DataFrame(history)\n",
    "history_save_path = os.path.join(config.data.output_dir, \"training_history.csv\")\n",
    "history_df.to_csv(history_save_path, index=False)\n",
    "logger.info(f\"Training history saved to: {history_save_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All results saved successfully!\")\n",
    "print(f\"Output directory: {config.data.output_dir}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
